# 美赛

## 资料

word输入公式：https://feigeek.com/posts/90904326.html latex数学符号：https://www.mohu.org/info/symbols/symbols.htm

强化学习代码https://aistudio.baidu.com/aistudio/projectdetail/2221634?channelType=0&channel=0&qq-pf-to=pcqq.group

历年优秀论文：[89-21年数模美赛O奖论文合集 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/452353086)

论文写作之参考文献：https://zhuanlan.zhihu.com/p/31954914

### 双均线

https://www.investopedia.com/terms/s/sma.asp

知乎双均线：https://zhuanlan.zhihu.com/p/21496174



## 参考文献

- 时间序列模型的机器交易和 投资组合优化

https://sci-hub.wf/10.1109/INCIT.2019.8912015 翻译：file:///D:/Download/INCIT.2019.8912015%20(1).pdf

评估性能的指标：均方误差

- 股票时间序列预测的深度学习[原文](chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=https%3A%2F%2Fdeliverypdf.ssrn.com%2Fdelivery.php%3FID%3D780025027093085078005102093107125031007048068055025069102113085123091068028113006024007063049014102035101119124090088031029064000033062052083124078123070003087077090005062075025077122065104095095079118116026116008028087025111103023001109123097078117098%26EXT%3Dpdf%26INDEX%3DTRUE)

- 使用网络和偏微分方程来预测比特币价格https://arxiv.org/abs/2001.03099
- 自适应量化交易：一种模仿的深度强化学习方法https://ojs.aaai.org/index.php/AAAI/article/view/5587

## 题目

![img](file:///C:\Users\lenovo\Documents\Tencent Files\1067095308\Image\Group2\GU\VO\GUVOA0H%ESO]Y``}{LVNMMG.png)







第一题：

传统：双线模型（黄金和比特币），布林带模型（暂时不用），机器学习（暂定svm）

强化学习



第二题：

收益情况，

stock



第三题：



summary 

our work

notions

为了形成投资策略并进行资产配置，我们需要预测回报并优化市场影响。在图像识别和自然语言处理等领域取得巨大成功之后，机器学习模型在过去五年中在金融应用中也获得了发展势头，这些模型已被证明对非结构化数据建模非常有用。除此之外，机器学习模型可以对分类和回归问题中的非线性进行建模，并在监督学习中发现隐藏结构。在金融中使用机器学习中的挑战也很多一个难以接受的问题是模型的可解释性，或者说机器学习模型倾向于过度拟合。而强化学习架构的建模优势之一是不仅能利用现有数据，还可以通过对环境的探索获得新数据，并利用新数据循环往复地更新迭代现有模型的机器学习算法，能够对非线性高维问题进行建模，也能通过学习更好地对环境进行探索近一步获取数据用于学习。

强化学习的基本要素包括[智能体](https://paddlepedia.readthedocs.io/en/latest/tutorials/reinforcement_learning/basic_information.html)、[环境](https://paddlepedia.readthedocs.io/en/latest/tutorials/reinforcement_learning/basic_information.html)、[状态](https://paddlepedia.readthedocs.io/en/latest/tutorials/reinforcement_learning/basic_information.html)、[动作](https://paddlepedia.readthedocs.io/en/latest/tutorials/reinforcement_learning/basic_information.html)、[策略](https://paddlepedia.readthedocs.io/en/latest/tutorials/reinforcement_learning/basic_information.html)和[奖励](https://paddlepedia.readthedocs.io/en/latest/tutorials/reinforcement_learning/basic_information.html)；在此问题下，人即为智能体，交易市场为环境，人通过对做出决策，即与环境交互后，会获得交易市场当前的状态。